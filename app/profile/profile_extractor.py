"""
Profile Extractor - Extracts structured and semantic data from user messages.

Implements:
1. RegEx extraction for structured fields (age, weight, height)
2. LLM classification for semantic facts
3. Occupation categorization
4. Confirmation generation for sensitive facts

Georgian patterns supported:
- Age: "40 áƒ¬áƒšáƒ˜áƒ¡", "40 áƒ¬"
- Weight: "85 áƒ™áƒ’", "85 áƒ™áƒ˜áƒšáƒ"
- Height: "180 áƒ¡áƒ›", "180 áƒ¡áƒáƒœáƒ¢áƒ˜"
- Occupation: "áƒ‘áƒáƒœáƒ™áƒ¨áƒ˜ áƒ•áƒ›áƒ£áƒ¨áƒáƒáƒ‘", "áƒ‘áƒáƒœáƒ™áƒ˜áƒ áƒ˜ áƒ•áƒáƒ "
"""

import re
import logging
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass, field
from datetime import datetime

logger = logging.getLogger(__name__)


# =============================================================================
# LATIN â†’ GEORGIAN TRANSLITERATION
# =============================================================================

# Common Latin phonetic spellings â†’ Georgian equivalents
LATIN_TO_GEORGIAN = {
    # Age-related
    "wlis": "áƒ¬áƒšáƒ˜áƒ¡",
    "weli": "áƒ¬áƒ”áƒšáƒ˜",
    "wl": "áƒ¬",
    # Weight-related  
    "kg": "áƒ™áƒ’",
    "kilo": "áƒ™áƒ˜áƒšáƒ",
    "viwoni": "áƒ•áƒ˜áƒ¬áƒáƒœáƒ˜",
    "wona": "áƒ¬áƒáƒœáƒ",
    # Height-related
    "sm": "áƒ¡áƒ›",
    "santi": "áƒ¡áƒáƒœáƒ¢áƒ˜",
    "santimetri": "áƒ¡áƒáƒœáƒ¢áƒ˜áƒ›áƒ”áƒ¢áƒ áƒ˜",
    "simaghle": "áƒ¡áƒ˜áƒ›áƒáƒ¦áƒšáƒ”",
    # Common verbs
    "var": "áƒ•áƒáƒ ",
    "vmushaobi": "áƒ•áƒ›áƒ£áƒ¨áƒáƒáƒ‘",
    "vmushaoĞ±": "áƒ•áƒ›áƒ£áƒ¨áƒáƒáƒ‘",
    "maqvs": "áƒ›áƒáƒ¥áƒ•áƒ¡",
    "minda": "áƒ›áƒ˜áƒœáƒ“áƒ",
    # Occupation keywords
    "bankshi": "áƒ‘áƒáƒœáƒ™áƒ¨áƒ˜",
    "mzareuli": "áƒ›áƒ–áƒáƒ áƒ”áƒ£áƒšáƒ˜",
    "programisti": "áƒáƒ áƒáƒ’áƒ áƒáƒ›áƒ˜áƒ¡áƒ¢áƒ˜",
    "mdzgholi": "áƒ›áƒ«áƒ¦áƒáƒšáƒ˜",
    "mshenebeli": "áƒ›áƒ¨áƒ”áƒœáƒ”áƒ‘áƒ”áƒšáƒ˜",
    "ofisshi": "áƒáƒ¤áƒ˜áƒ¡áƒ¨áƒ˜",
}


def apply_transliteration(text: str) -> str:
    """
    Convert common Latin phonetic spellings to Georgian.
    
    This allows users to type in Latin script while enabling
    RegEx patterns to match Georgian keywords.
    
    Example:
        "50 wlis var" â†’ "50 áƒ¬áƒšáƒ˜áƒ¡ áƒ•áƒáƒ "
    """
    result = text.lower()
    
    # Sort by length descending to match longer phrases first
    for latin, georgian in sorted(LATIN_TO_GEORGIAN.items(), key=lambda x: -len(x[0])):
        result = result.replace(latin, georgian)
    
    return result

# =============================================================================
# DATA CLASSES
# =============================================================================

@dataclass
class ExtractionResult:
    """Result of profile extraction from a message."""
    demographics: Dict[str, Any] = field(default_factory=dict)
    physical_stats: Dict[str, Any] = field(default_factory=dict)
    lifestyle: Dict[str, Any] = field(default_factory=dict)
    potential_facts: List[str] = field(default_factory=list)
    confirmations: List[str] = field(default_factory=list)
    has_updates: bool = False


# =============================================================================
# REGEX PATTERNS (Georgian)
# =============================================================================

# Age patterns: "40 áƒ¬áƒšáƒ˜áƒ¡", "40áƒ¬", "áƒ•áƒáƒ  40 áƒ¬áƒšáƒ˜áƒ¡"
AGE_PATTERNS = [
    r'(\d{1,2})\s*áƒ¬áƒšáƒ˜áƒ¡',           # 40 áƒ¬áƒšáƒ˜áƒ¡
    r'(\d{1,2})\s*áƒ¬(?:[^\w]|$)',   # 40áƒ¬ (with non-word or end-of-string)
    r'áƒ•áƒáƒ \s*(\d{1,2})\s*áƒ¬áƒšáƒ˜áƒ¡',     # áƒ•áƒáƒ  40 áƒ¬áƒšáƒ˜áƒ¡
    r'(\d{1,2})\s*áƒ¬áƒšáƒ˜áƒ¡\s*áƒ•áƒáƒ ',     # 40 áƒ¬áƒšáƒ˜áƒ¡ áƒ•áƒáƒ 
]

# Weight patterns: "85 áƒ™áƒ’", "85 áƒ™áƒ˜áƒšáƒ", "áƒ•áƒ˜áƒ¬áƒáƒœáƒ˜ 85"
WEIGHT_PATTERNS = [
    r'(\d{2,3})\s*áƒ™áƒ’',             # 85 áƒ™áƒ’
    r'(\d{2,3})\s*áƒ™áƒ˜áƒšáƒ',           # 85 áƒ™áƒ˜áƒšáƒ
    r'áƒ•áƒ˜áƒ¬áƒáƒœáƒ˜\s*(\d{2,3})',         # áƒ•áƒ˜áƒ¬áƒáƒœáƒ˜ 85
    r'áƒ¬áƒáƒœáƒ.*?(\d{2,3})',           # áƒ¬áƒáƒœáƒ 85
]

# Height patterns: "180 áƒ¡áƒ›", "180 áƒ¡áƒáƒœáƒ¢áƒ˜"
HEIGHT_PATTERNS = [
    r'(\d{3})\s*áƒ¡áƒ›',               # 180 áƒ¡áƒ›
    r'(\d{3})\s*áƒ¡áƒáƒœáƒ¢áƒ˜',            # 180 áƒ¡áƒáƒœáƒ¢áƒ˜
    r'áƒ¡áƒ˜áƒ›áƒáƒ¦áƒšáƒ”.*?(\d{3})',          # áƒ¡áƒ˜áƒ›áƒáƒ¦áƒšáƒ” 180
]

# Occupation keywords â†’ category mapping
OCCUPATION_KEYWORDS = {
    "sedentary": [
        "áƒ‘áƒáƒœáƒ™", "áƒáƒ¤áƒ˜áƒ¡", "áƒ™áƒáƒ›áƒáƒ˜áƒ£áƒ¢áƒ”áƒ ", "áƒáƒ áƒáƒ’áƒ áƒáƒ›", "áƒ‘áƒ£áƒ¦áƒáƒšáƒ¢", 
        "áƒ˜áƒ£áƒ áƒ˜áƒ¡áƒ¢", "áƒáƒ“áƒ•áƒáƒ™áƒáƒ¢", "áƒ›áƒ”áƒœáƒ”áƒ¯áƒ”áƒ ", "áƒ¡áƒ”áƒ¥áƒ áƒ”áƒ¢áƒáƒ ", "áƒ“áƒ˜áƒ–áƒáƒ˜áƒœáƒ”áƒ ",
        "it-", "áƒáƒ˜áƒ—áƒ˜", "áƒ“áƒ”áƒ•áƒ”áƒšáƒáƒáƒ”áƒ ", "áƒ˜áƒœáƒŸáƒ˜áƒœáƒ”áƒ "  # IT sector
    ],
    "light": [
        "áƒ›áƒáƒ¦áƒáƒ–áƒ˜áƒ", "áƒ’áƒáƒ›áƒ§áƒ˜áƒ“áƒ•áƒ”áƒš", "áƒ›áƒáƒ¡áƒ¬áƒáƒ•áƒšáƒ”áƒ‘", "áƒ”áƒ¥áƒ˜áƒ›", "áƒ”áƒ¥áƒ—áƒáƒœ",
        "áƒ›áƒ–áƒáƒ áƒ”áƒ£áƒš", "áƒ¨áƒ”áƒ¤", "áƒ›áƒªáƒ®áƒáƒ‘áƒ”áƒš"  # Food service
    ],
    "active": [
        "áƒ›áƒ«áƒ¦áƒáƒš", "áƒ™áƒ£áƒ áƒ˜áƒ”áƒ ", "áƒáƒ¤áƒ˜áƒªáƒ”áƒ ", "áƒáƒáƒšáƒ˜áƒªáƒ˜", "áƒ›áƒ¬áƒ•áƒ áƒ—áƒœáƒ”áƒš"
    ],
    "heavy": [
        "áƒ›áƒ¨áƒ”áƒœáƒ”áƒ‘", "áƒ¤áƒ”áƒ áƒ›", "áƒ›áƒ”áƒ®áƒáƒœáƒ«áƒ ", "áƒ¡áƒáƒáƒ áƒ¢áƒ¡áƒ›áƒ”áƒœ", 
        "áƒ›áƒ”áƒ¢áƒ§áƒ”áƒ•áƒ”", "áƒ›áƒ”áƒ¦áƒ•áƒ˜áƒœáƒ”", "áƒ›áƒ­áƒ”áƒ“áƒ”áƒš", "áƒ¢áƒ•áƒ˜áƒ áƒ—áƒ›áƒ–áƒ˜áƒ“"  # Heavy labor (removed "áƒ›áƒ£áƒ¨áƒ" - false positive with "áƒ•áƒ›áƒ£áƒ¨áƒáƒáƒ‘")
    ]
}

# Sensitive keywords (require confirmation)
SENSITIVE_KEYWORDS = [
    "áƒáƒ áƒ¡áƒ£áƒš", "áƒ¤áƒ”áƒ®áƒ›áƒ«áƒ˜áƒ›",           # Pregnancy
    "áƒ“áƒ˜áƒáƒ‘áƒ”áƒ¢", "áƒ¨áƒáƒ¥áƒ áƒ˜áƒáƒœ",          # Diabetes
    "áƒ’áƒ£áƒšáƒ˜", "áƒáƒ áƒ˜áƒ—áƒ›áƒ˜áƒ",            # Heart conditions
    "áƒáƒšáƒ”áƒ áƒ’áƒ˜áƒ",                     # Allergies (may need explicit handling)
    "áƒ¢áƒ áƒáƒ•áƒ›áƒ", "áƒ›áƒáƒ¢áƒ”áƒ®áƒ˜áƒšáƒ˜", "áƒ“áƒáƒ–áƒ˜áƒáƒœáƒ”áƒ‘"  # Injuries
]

# Fact indicator phrases (semantic memory candidates)
FACT_INDICATORS = [
    r'áƒ›áƒáƒ¥áƒ•áƒ¡\s+(.{10,})',          # "áƒ›áƒáƒ¥áƒ•áƒ¡..."
    r'áƒ›áƒ¢áƒ™áƒ˜áƒ•áƒ\s+(.{5,})',          # "áƒ›áƒ¢áƒ™áƒ˜áƒ•áƒ..."
    r'áƒáƒ \s+áƒ¨áƒ”áƒ›áƒ˜áƒ«áƒšáƒ˜áƒ\s+(.{5,})',   # "áƒáƒ  áƒ¨áƒ”áƒ›áƒ˜áƒ«áƒšáƒ˜áƒ..."
    r'áƒáƒ áƒáƒ‘áƒšáƒ”áƒ›áƒ.*?(.{10,})',       # "áƒáƒ áƒáƒ‘áƒšáƒ”áƒ›áƒ..."
    r'áƒ£áƒ§áƒ•áƒáƒ áƒ¡\s+(.{5,})',          # "áƒ£áƒ§áƒ•áƒáƒ áƒ¡..."
    r'áƒáƒ \s+áƒ£áƒ§áƒ•áƒáƒ áƒ¡\s+(.{5,})',     # "áƒáƒ  áƒ£áƒ§áƒ•áƒáƒ áƒ¡..."
]

# =============================================================================
# NEGATION HANDLING (LLM Verification Triggers)
# =============================================================================

# Georgian negation patterns that require LLM verification
NEGATION_TRIGGERS = [
    'áƒáƒ  áƒ•áƒáƒ ',      # "áƒáƒ  áƒ•áƒáƒ  20 áƒ¬áƒšáƒ˜áƒ¡" = NOT 20 years old
    'áƒ™áƒ˜ áƒáƒ áƒ',      # "20 áƒ™áƒ˜ áƒáƒ áƒ, 30" = NOT 20, but 30
    'áƒáƒ¦áƒáƒ ',        # "áƒáƒ¦áƒáƒ  áƒ•áƒáƒ " = no longer
    'áƒáƒ áƒ áƒ•áƒáƒ ',     # Alternative negation
    'áƒ“áƒáƒ•áƒ™áƒáƒ áƒ’áƒ”',    # "áƒ“áƒáƒ•áƒ™áƒáƒ áƒ’áƒ” áƒ¡áƒáƒ›áƒ¡áƒáƒ®áƒ£áƒ áƒ˜" = lost job
    'áƒ¬áƒáƒ•áƒ”áƒ“áƒ˜',      # "áƒ¬áƒáƒ•áƒ”áƒ“áƒ˜ áƒ‘áƒáƒœáƒ™áƒ˜áƒ“áƒáƒœ" = left bank
    'áƒáƒ¦áƒáƒ áƒ',       # Shorter negation form
    'áƒ•áƒ˜áƒ§áƒáƒ•áƒ˜',      # "áƒ‘áƒáƒœáƒ™áƒ˜áƒ áƒ˜ áƒ•áƒ˜áƒ§áƒáƒ•áƒ˜" = was banker (past)
    'áƒáƒ“áƒ áƒ”',        # "áƒáƒ“áƒ áƒ” áƒ•áƒ›áƒ£áƒ¨áƒáƒáƒ‘áƒ“áƒ˜" = used to work
]

# Context triggers (reference to others, not self)
CONTEXT_TRIGGERS = [
    'áƒ¨áƒ•áƒ˜áƒš',        # Child ("áƒ©áƒ”áƒ›áƒ˜ áƒ¨áƒ•áƒ˜áƒšáƒ˜áƒ 10 áƒ¬áƒšáƒ˜áƒ¡")
    'áƒ«áƒ›áƒ',         # Brother
    'áƒ“áƒ',          # Sister (also means "and" - context needed)
    'áƒ›áƒ¨áƒáƒ‘',        # Parent
    'áƒ›áƒ”áƒ’áƒáƒ‘',       # Friend
]


# =============================================================================
# PROFILE EXTRACTOR
# =============================================================================

class ProfileExtractor:
    """
    Extracts user profile information from messages.
    
    Usage:
        extractor = ProfileExtractor()
        result = extractor.extract("40 áƒ¬áƒšáƒ˜áƒ¡ áƒ•áƒáƒ  áƒ“áƒ áƒ‘áƒáƒœáƒ™áƒ¨áƒ˜ áƒ•áƒ›áƒ£áƒ¨áƒáƒáƒ‘")
        # result.demographics = {"age": 40, "occupation": "áƒ‘áƒáƒœáƒ™áƒ¨áƒ˜ áƒ•áƒ›áƒ£áƒ¨áƒáƒáƒ‘", "occupation_category": "sedentary"}
    """
    
    def __init__(self):
        # Compile patterns for efficiency
        self.age_patterns = [re.compile(p, re.IGNORECASE | re.UNICODE) for p in AGE_PATTERNS]
        self.weight_patterns = [re.compile(p, re.IGNORECASE | re.UNICODE) for p in WEIGHT_PATTERNS]
        self.height_patterns = [re.compile(p, re.IGNORECASE | re.UNICODE) for p in HEIGHT_PATTERNS]
        self.fact_patterns = [re.compile(p, re.IGNORECASE | re.UNICODE) for p in FACT_INDICATORS]
    
    def extract(self, message: str) -> ExtractionResult:
        """
        Extract all profile information from a message.
        
        Args:
            message: User message text
            
        Returns:
            ExtractionResult with extracted data
        """
        result = ExtractionResult()
        
        # Pre-process: Apply Latin â†’ Georgian transliteration
        # This allows users to type e.g. "50 wlis var" instead of "50 áƒ¬áƒšáƒ˜áƒ¡ áƒ•áƒáƒ "
        processed_message = apply_transliteration(message)
        
        # 1. Extract structured data (use processed message for pattern matching)
        age = self._extract_age(processed_message)
        if age:
            result.demographics["age"] = age
            result.has_updates = True
        
        weight = self._extract_weight(processed_message)
        if weight:
            result.physical_stats["weight"] = weight
            result.has_updates = True
        
        height = self._extract_height(processed_message)
        if height:
            result.physical_stats["height"] = height
            result.has_updates = True
        
        # 2. Extract occupation
        occupation = self._extract_occupation(processed_message)
        if occupation:
            result.demographics["occupation"] = occupation["text"]
            result.demographics["occupation_category"] = occupation["category"]
            result.has_updates = True
        
        # 3. Extract potential facts (use original message to preserve user's words)
        facts = self._extract_potential_facts(message)
        if facts:
            result.potential_facts = facts
            result.has_updates = True
        
        # 4. Check for sensitive information (use original message)
        sensitive = self._check_sensitive(message)
        if sensitive:
            result.confirmations = sensitive
        
        return result
    
    def _extract_age(self, message: str) -> Optional[int]:
        """Extract age from message."""
        for pattern in self.age_patterns:
            match = pattern.search(message)
            if match:
                age = int(match.group(1))
                if 10 <= age <= 120:  # Reasonable age range
                    return age
        return None
    
    def _extract_weight(self, message: str) -> Optional[float]:
        """Extract weight (kg) from message.
        
        Smart negation handling: If message contains negation pattern like
        "90 áƒ™áƒ˜áƒšáƒ áƒ™áƒ˜ áƒáƒ  áƒ•áƒáƒ , 85 áƒ™áƒ˜áƒšáƒ áƒ•áƒáƒ ", use the LAST valid match (85)
        instead of the first (90). This avoids LLM verification latency.
        """
        all_weights = []
        
        for pattern in self.weight_patterns:
            matches = pattern.finditer(message)
            for match in matches:
                weight = float(match.group(1))
                if 30 <= weight <= 300:  # Reasonable weight range
                    all_weights.append((weight, match.start()))
        
        if not all_weights:
            return None
        
        # Smart negation handling: use LAST weight when negation detected
        if has_negation(message) and len(all_weights) > 1:
            # Sort by position, take last one (the corrected value)
            all_weights.sort(key=lambda x: x[1])
            logger.info(f"ğŸ”„ Negation detected, using last weight: {all_weights[-1][0]} (rejected: {all_weights[0][0]})")
            return all_weights[-1][0]
        
        # Default: return first match
        return all_weights[0][0]
    
    def _extract_height(self, message: str) -> Optional[float]:
        """Extract height (cm) from message."""
        for pattern in self.height_patterns:
            match = pattern.search(message)
            if match:
                height = float(match.group(1))
                if 100 <= height <= 250:  # Reasonable height range
                    return height
        return None
    
    def _extract_occupation(self, message: str) -> Optional[Dict[str, str]]:
        """
        Extract occupation with conflict resolution.
        
        Uses "Negation-Aware Last Match Wins" algorithm:
        1. Find ALL occupation candidates with positions
        2. If negation detected near a candidate, skip it
        3. Return remaining candidate (or last by position if no negation)
        
        Examples:
            "áƒ‘áƒáƒœáƒ™áƒ¨áƒ˜ áƒáƒ¦áƒáƒ  áƒ•áƒ›áƒ£áƒ¨áƒáƒáƒ‘, áƒ›áƒ–áƒáƒ áƒ”áƒ£áƒšáƒ˜ áƒ•áƒáƒ " â†’ áƒ›áƒ–áƒáƒ áƒ”áƒ£áƒšáƒ˜ ("áƒ‘áƒáƒœáƒ™áƒ¨áƒ˜" skipped due to "áƒáƒ¦áƒáƒ ")
            "áƒ›áƒ–áƒáƒ áƒ”áƒ£áƒšáƒ˜ áƒ•áƒáƒ " â†’ áƒ›áƒ–áƒáƒ áƒ”áƒ£áƒšáƒ˜ (single candidate)
        
        Returns:
            {"text": "occupation context", "category": "sedentary|active|physical"}
        """
        message_lower = message.lower()
        candidates = []
        
        # 1. Find ALL candidates with positions
        for category, keywords in OCCUPATION_KEYWORDS.items():
            for keyword in keywords:
                if keyword in message_lower:
                    idx = message_lower.find(keyword)
                    # Extract surrounding context
                    start = max(0, idx - 20)
                    end = min(len(message), idx + len(keyword) + 20)
                    occupation_text = message[start:end].strip()
                    
                    candidates.append({
                        "keyword": keyword,
                        "position": idx,
                        "category": category,
                        "text": occupation_text
                    })
        
        if not candidates:
            return None
        
        # 2. Single candidate - return directly
        if len(candidates) == 1:
            cand = candidates[0]
            # Use keyword as occupation text (not full context to avoid negation words)
            return {"text": cand["keyword"], "category": cand["category"]}
        
        # 3. Multiple candidates - check for negation
        if has_negation(message):
            # Find earliest negation position
            negation_pos = -1
            for trigger in NEGATION_TRIGGERS:
                pos = message_lower.find(trigger)
                if pos != -1 and (negation_pos == -1 or pos < negation_pos):
                    negation_pos = pos
            
            # Filter out candidates near negation (within 30 chars)
            valid_candidates = [
                c for c in candidates 
                if abs(c["position"] - negation_pos) > 30
            ]
            
            if valid_candidates:
                # Return first valid (non-negated) candidate by position
                valid_candidates.sort(key=lambda x: x["position"])
                cand = valid_candidates[0]
                # Use keyword as occupation text (not context to avoid confusion)
                return {"text": cand["keyword"], "category": cand["category"]}
        
        # 4. No negation or all candidates valid - return LAST by position
        last_cand = max(candidates, key=lambda x: x["position"])
        # Use keyword as occupation text
        return {"text": last_cand["keyword"], "category": last_cand["category"]}
    
    def _extract_potential_facts(self, message: str) -> List[str]:
        """Extract potential semantic facts from message."""
        facts = []
        
        for pattern in self.fact_patterns:
            matches = pattern.findall(message)
            for match in matches:
                if len(match) >= 10:  # Minimum fact length
                    facts.append(match.strip())
        
        return facts
    
    def _check_sensitive(self, message: str) -> List[str]:
        """Check for sensitive information that needs confirmation."""
        confirmations = []
        message_lower = message.lower()
        
        for keyword in SENSITIVE_KEYWORDS:
            if keyword in message_lower:
                confirmations.append(
                    f"áƒ“áƒáƒ•áƒ˜áƒ›áƒáƒ®áƒ¡áƒáƒ•áƒ áƒ” áƒ˜áƒœáƒ¤áƒáƒ áƒ›áƒáƒªáƒ˜áƒ: \"{keyword}\" - áƒáƒ›áƒ˜áƒ¡ áƒ’áƒáƒ—áƒ•áƒáƒšáƒ˜áƒ¡áƒ¬áƒ˜áƒœáƒ”áƒ‘áƒ˜áƒ— áƒ›áƒáƒ’áƒªáƒ”áƒ›áƒ— áƒ áƒ©áƒ”áƒ•áƒ”áƒ‘áƒ¡."
                )
        
        return confirmations
    
    def generate_confirmation(self, result: ExtractionResult) -> Optional[str]:
        """
        Generate confirmation message for extracted data.
        
        Used for explicit confirmation (user feedback recommendation).
        """
        parts = []
        
        if result.demographics.get("age"):
            parts.append(f"áƒáƒ¡áƒáƒ™áƒ˜: {result.demographics['age']} áƒ¬áƒ”áƒšáƒ˜")
        
        if result.physical_stats.get("weight"):
            parts.append(f"áƒ¬áƒáƒœáƒ: {result.physical_stats['weight']} áƒ™áƒ’")
        
        if result.physical_stats.get("height"):
            parts.append(f"áƒ¡áƒ˜áƒ›áƒáƒ¦áƒšáƒ”: {result.physical_stats['height']} áƒ¡áƒ›")
        
        if result.demographics.get("occupation"):
            parts.append(f"áƒáƒ áƒáƒ¤áƒ”áƒ¡áƒ˜áƒ: {result.demographics['occupation']}")
        
        if parts:
            return "áƒ˜áƒœáƒ¤áƒáƒ áƒ›áƒáƒªáƒ˜áƒ áƒ“áƒáƒ•áƒ˜áƒ›áƒáƒ®áƒ¡áƒáƒ•áƒ áƒ”: " + ", ".join(parts)
        
        if result.confirmations:
            return result.confirmations[0]
        
        return None


# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

def is_long_term_fact(message: str) -> bool:
    """
    Heuristic check if a statement is a long-term fact.
    
    This is a simple heuristic; for production, use LLM classification.
    """
    # Temporary indicators (NOT long-term facts)
    temporary_keywords = [
        "áƒ“áƒ¦áƒ”áƒ¡", "áƒáƒ®áƒšáƒ", "áƒ”áƒ®áƒšáƒ", "áƒáƒ› áƒ¬áƒ£áƒ—áƒáƒ¡", "áƒ”áƒ¡ áƒ™áƒ•áƒ˜áƒ áƒ", 
        "áƒ’áƒ£áƒ¨áƒ˜áƒœ", "áƒ–áƒ”áƒ’", "áƒ®áƒ•áƒáƒš"
    ]
    
    message_lower = message.lower()
    
    # If contains temporary indicators, less likely to be long-term
    for keyword in temporary_keywords:
        if keyword in message_lower:
            return False
    
    # Long-term indicators
    long_term_keywords = [
        "áƒ§áƒáƒ•áƒ”áƒšáƒ—áƒ•áƒ˜áƒ¡", "áƒ®áƒ¨áƒ˜áƒ áƒáƒ“", "áƒ©áƒ•áƒ”áƒ£áƒšáƒ”áƒ‘áƒ áƒ˜áƒ•", "áƒ¬áƒšáƒ”áƒ‘áƒ˜áƒ", 
        "áƒ›áƒ£áƒ“áƒ›áƒ˜áƒ•áƒáƒ“", "áƒ©áƒ”áƒ›áƒ—áƒ•áƒ˜áƒ¡", "áƒ›áƒ˜áƒ§áƒ•áƒáƒ áƒ¡", "áƒáƒ  áƒ›áƒ˜áƒ§áƒ•áƒáƒ áƒ¡"
    ]
    
    for keyword in long_term_keywords:
        if keyword in message_lower:
            return True
    
    # Default: check length (longer statements more likely to be facts)
    return len(message) > 30


def has_negation(text: str) -> bool:
    """
    Check if text contains Georgian negation patterns.
    
    Used to trigger LLM verification for extracted values.
    
    Args:
        text: User message text
        
    Returns:
        True if negation pattern detected
    """
    text_lower = text.lower()
    return any(trigger in text_lower for trigger in NEGATION_TRIGGERS)


def has_context_reference(text: str) -> bool:
    """
    Check if text references another person (child, sibling, etc.).
    
    Used to avoid extracting someone else's data as user's data.
    
    Args:
        text: User message text
        
    Returns:
        True if context reference detected
    """
    text_lower = text.lower()
    return any(trigger in text_lower for trigger in CONTEXT_TRIGGERS)


async def verify_fact_with_llm(
    text: str,
    field: str,
    extracted_value: Any,
    timeout: float = 0.5
) -> Optional[Any]:
    """
    Verify extracted value using Gemini Flash LLM.
    
    Called when negation is detected to disambiguate values.
    
    Args:
        text: Original user message
        field: Field name (age, weight, height)
        extracted_value: Value extracted by RegEx
        timeout: Max time for LLM call (default 500ms)
        
    Returns:
        Verified value if different, None if extraction should be rejected,
        or original value if LLM confirms
    """
    import asyncio
    import logging
    
    logger = logging.getLogger(__name__)
    
    try:
        # Import Gemini client
        from google import genai
        from config import settings
        
        client = genai.Client(api_key=settings.gemini_api_key)
        
        # Construct verification prompt (Georgian-aware)
        prompt = f"""áƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ¨áƒ˜ áƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒšáƒ˜áƒ¡ {field} áƒ£áƒœáƒ“áƒ áƒáƒ›áƒáƒ•áƒ˜áƒ¦áƒáƒ—.

áƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜: "{text}"
RegEx-áƒ›áƒ áƒáƒ›áƒáƒ˜áƒ¦áƒ: {extracted_value}

áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ: áƒ áƒ áƒáƒ áƒ˜áƒ¡ áƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒšáƒ˜áƒ¡ áƒœáƒáƒ›áƒ“áƒ•áƒ˜áƒšáƒ˜ {field}? 
- áƒ—áƒ£ {extracted_value} áƒ¡áƒ¬áƒáƒ áƒ˜áƒ, áƒ“áƒáƒáƒ‘áƒ áƒ£áƒœáƒ”: {extracted_value}
- áƒ—áƒ£ áƒ¡áƒ®áƒ•áƒ áƒ›áƒœáƒ˜áƒ¨áƒ•áƒœáƒ”áƒšáƒáƒ‘áƒáƒ áƒ¡áƒ¬áƒáƒ áƒ˜, áƒ“áƒáƒáƒ‘áƒ áƒ£áƒœáƒ” áƒ˜áƒ¡ áƒ áƒ˜áƒªáƒ®áƒ•áƒ˜
- áƒ—áƒ£ áƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒ”áƒšáƒ˜ áƒáƒ  áƒ¡áƒáƒ£áƒ‘áƒ áƒáƒ‘áƒ¡ áƒ¡áƒáƒ™áƒ£áƒ—áƒáƒ  áƒ—áƒáƒ•áƒ–áƒ”, áƒ“áƒáƒáƒ‘áƒ áƒ£áƒœáƒ”: null

áƒ›áƒ®áƒáƒšáƒáƒ“ áƒ áƒ˜áƒªáƒ®áƒ•áƒ˜ áƒáƒœ null áƒ“áƒáƒáƒ‘áƒ áƒ£áƒœáƒ”, áƒáƒ áƒáƒ¤áƒ”áƒ áƒ˜ áƒ¡áƒ®áƒ•áƒ."""

        # Call Gemini Flash with timeout
        response = await asyncio.wait_for(
            asyncio.to_thread(
                client.models.generate_content,
                model="gemini-2.0-flash",  # Fast model for verification
                contents=prompt,
            ),
            timeout=timeout
        )
        
        result_text = response.text.strip().lower()
        
        # Parse response
        if result_text == 'null' or result_text == 'none':
            logger.info(f"ğŸ” LLM rejected extraction: {field}={extracted_value} (not user's data)")
            return None
        
        try:
            verified_value = int(result_text) if field == 'age' else float(result_text)
            if verified_value != extracted_value:
                logger.info(f"ğŸ” LLM corrected: {field}={verified_value} (was {extracted_value})")
            else:
                logger.debug(f"ğŸ” LLM confirmed: {field}={extracted_value}")
            return verified_value
        except ValueError:
            # LLM returned non-numeric, trust original extraction
            logger.warning(f"âš ï¸ LLM returned invalid value '{result_text}', using RegEx result")
            return extracted_value
            
    except asyncio.TimeoutError:
        logger.warning(f"âš ï¸ LLM verification timeout ({timeout}s), using RegEx result")
        return extracted_value
    except Exception as e:
        logger.error(f"âŒ LLM verification error: {e}, using RegEx result")
        return extracted_value
